{
  "unity_paths": {
    "Windows": "builds/windows/tetris/tetris-multi.exe",
    "Linux": "builds/linux/tetris.x86_64",
    "Darwin": "builds/mac/tetris-full-curriculum-dummy.app/Contents/MacOS/tetris-multi"
  },
  "host": "127.0.0.1",
  "log_dir": "logs",
  "reward_config": {
    "heuristic_stack_height_coeff": -0.51,
    "heuristic_line_coeff": 5.0,
    "heuristic_holes_coeff": -0.36,
    "heuristic_bumpiness_coeff": -0.18,
    "shaped_base": 0.2,
    "shaped_holes_coeff": 0.25,
    "shaped_bumpiness_coeff": 0.1,
    "shaped_wells_coeff": 0.1,
    "height_reward_threshold": 10,
    "height_reward_multiplier": 0.5,
    "height_penalty_threshold": 16,
    "height_penalty_multiplier": 3.0,
    "normalization_divisor": 50.0,
    "clip_min": -1.0,
    "clip_max": 1.0,
    "lines_multiplier": 75
  },
  "agent_params": {
    "learning_rate": 3e-4,
    "gamma": 0.99
  },

  "sb3_params": {
    "common": {
      "verbose": 1,
      "device": "auto",
      "seed": 42
    },
    "ppo": {
      "learning_rate": 3e-4,
      "n_steps": 2048,
      "batch_size": 64,
      "n_epochs": 10,
      "gamma": 0.99,
      "gae_lambda": 0.95,
      "clip_range": 0.2,
      "clip_range_vf": null,
      "ent_coef": 0.01,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5,
      "use_sde": false,
      "sde_sample_freq": -1,
      "target_kl": null
    },
    "dqn": {
      "learning_rate": 1e-4,
      "buffer_size": 100000,
      "learning_starts": 50000,
      "batch_size": 32,
      "tau": 1.0,
      "gamma": 0.99,
      "train_freq": 4,
      "gradient_steps": 1,
      "target_update_interval": 10000,
      "exploration_fraction": 0.1,
      "exploration_initial_eps": 1.0,
      "exploration_final_eps": 0.05,
      "max_grad_norm": 10
    },
    "a2c": {
      "learning_rate": 7e-4,
      "n_steps": 5,
      "gamma": 0.99,
      "gae_lambda": 1.0,
      "ent_coef": 0.0,
      "vf_coef": 0.25,
      "max_grad_norm": 0.5,
      "rms_prop_eps": 1e-5,
      "use_rms_prop": true,
      "use_sde": false,
      "sde_sample_freq": -1,
      "normalize_advantage": false
    }
  },
  "instances": [
    {
      "name": "nuna",
      "port": 12359,
      "agent": "nuna",
      "reward_line_clear": 1.0,
      "reward_height": -0.1,
      "reward_holes": -0.5,
      "episodes": 2000,
      "curriculum": false,
      "reward_config": { "lines_multiplier": 100 }
    }
  ]
}
