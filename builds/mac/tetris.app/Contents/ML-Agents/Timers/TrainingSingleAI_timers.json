{"count":1,"self":5.164098,"total":686.54176599999994,"children":{"InitializeActuators":{"count":1,"self":0.00091099999999999992,"total":0.00091099999999999992,"children":null},"InitializeSensors":{"count":1,"self":0.00065299999999999993,"total":0.00065299999999999993,"children":null},"AgentSendState":{"count":119067,"self":0.573356,"total":7.155619,"children":{"CollectObservations":{"count":119067,"self":2.538696,"total":2.538696,"children":null},"WriteActionMask":{"count":119067,"self":0.12189,"total":0.12189,"children":null},"RequestDecision":{"count":119067,"self":0.266247,"total":3.921677,"children":{"AgentInfo.ToProto":{"count":119067,"self":0.405234,"total":3.65543,"children":{"GenerateSensorData":{"count":119067,"self":3.250196,"total":3.250196,"children":null}}}}}}},"DecideAction":{"count":119067,"self":663.6146688,"total":663.614684,"children":null},"AgentAct":{"count":119067,"self":10.5992176,"total":10.599217999999999,"children":null},"AgentInfo.ToProto":{"count":177,"self":0.00086,"total":0.0058319999999999995,"children":{"GenerateSensorData":{"count":177,"self":0.004972,"total":0.004972,"children":null}}}},"gauges":{"TetrisAgent.CumulativeReward":{"count":177,"max":7170.057,"min":-2.61131573,"runningAverage":979.8649,"value":1055.54089,"weightedAverage":2010.56824}},"metadata":{"timer_format_version":"0.1.0","start_time_seconds":"1748601162","unity_version":"6000.0.47f1","command_line_arguments":"\/Users\/anandpatil\/Documents\/Projects\/ml-agent-train\/python\/.\/builds\/mac\/tetris.app\/Contents\/MacOS\/tetris-multi -nographics -batchmode --mlagents-port 5005 -logFile \/Users\/anandpatil\/Documents\/Projects\/ml-agent-train\/python\/results\/GA_Gen0_T1748601154_3372\/run_logs\/Player-0.log","communication_protocol_version":"1.5.0","com.unity.ml-agents_version":"3.0.0","scene_name":"TrainingSingleAI","end_time_seconds":"1748601848"}}"}}